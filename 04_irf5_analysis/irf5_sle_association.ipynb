{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e0818aa-b1ad-45fa-a27b-c5df81d5133d",
   "metadata": {},
   "source": [
    "## **IRF5 Region Association Analysis with SLE in UK Biobank WGS**\n",
    "This notebook extracts variants in the IRF5 gene region (±1Mb) from UK Biobank WGS data and tests for association with SLE using logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd3fd3d-e082-4bf9-8124-920e7bd3ac02",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Step 1: Install PLINK2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed1c9ac-56b3-4a1b-abcc-5e8c39a53705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install PLINK2\n",
    "wget https://s3.amazonaws.com/plink2-assets/alpha6/plink2_linux_avx2_20251019.zip\n",
    "unzip -o plink2_linux_avx2_20251019.zip\n",
    "chmod a+x plink2 # Make PLINK2 executable\n",
    "./plink2 --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aa22fc-f00b-4c23-8a94-cf7ce7fc71a3",
   "metadata": {},
   "source": [
    "### **Step 2: Set Variables**\n",
    "- IRF5 genomic location (GRCh38.p14): chr7:128,937,032-128,950,038"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f6edea-440a-4117-8d92-ec6acadffb78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List project folders to verify file paths\n",
    "ls /mnt/project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c612181b-17ad-4263-b624-7ee6f530f22a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Set IRF5 gene region variables\n",
    "CHR=7\n",
    "GENE_START=128937032\n",
    "GENE_END=128950038\n",
    "FLANK=1000000\n",
    "\n",
    "# Calculate region with flanking sequences\n",
    "REGION_START=$((GENE_START - FLANK))\n",
    "REGION_END=$((GENE_END + FLANK))\n",
    "\n",
    "## Set working directory & file path variables for input data\n",
    "BGEN_DIR=\"/mnt/project/Bulk/DRAGEN WGS/DRAGEN population level WGS variants, BGEN format [500k release]\"\n",
    "PHENO_FILE=\"/mnt/project/02.Phenotype_SampleQC/sle_gwas.txt\"\n",
    "KEEP_FILE=\"/mnt/project/02.Phenotype_SampleQC/sample_ids_qc_pass.txt\"\n",
    "EXTRACT_FILE=\"/mnt/project/03.Variant_QC/WGS_QC/ukb24309_c7_b0_v1_qc_pass.snplist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf7e916-2de4-427c-900a-db296bab6faf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspect sample ID format in the BGEN sample metadata file\n",
    "head -n 10 \"${BGEN_DIR}/ukb24309_c${CHR}_b0_v1.sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21494baa-3f1a-4176-8d7e-a56748c83c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspect sample ID format in WGS QC file - should match BGEN\n",
    "head -n 10 ${KEEP_FILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84056271-9293-4257-bd7a-6c19d23aa09f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspect QC Pass SNPs in WGS QC file\n",
    "head -n 10 ${EXTRACT_FILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56150d91-7dfe-43f6-99fb-9419eefcdaef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspect phenotypes files\n",
    "head -n 10 ${PHENO_FILE}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137539e8-a3bf-4453-8cf6-dd0a0b6df524",
   "metadata": {},
   "source": [
    "### **Step 3: Extract IRF5 Region (Only QC-Passed Variants & Samples)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed309c2-fc73-455f-8c85-f3939f10d4ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "./plink2 \\\n",
    "  --bgen \"${BGEN_DIR}/ukb24309_c${CHR}_b0_v1.bgen\" ref-last \\  # WGS data has last allele as ref\n",
    "  --sample \"${BGEN_DIR}/ukb24309_c${CHR}_b0_v1.sample\" \\ \n",
    "  --chr ${CHR} \\\n",
    "  --from-bp ${REGION_START} \\\n",
    "  --to-bp ${REGION_END} \\\n",
    "  --extract ${EXTRACT_FILE} \\  # Include only QC-passed variants\n",
    "  --keep ${KEEP_FILE} \\  # Include only QC-passed samples\n",
    "  --force-intersect \\\n",
    "  --make-pgen \\  # Create PLINK2 binary format (.pgen/.pvar/.psam)\n",
    "  --out irf5_region_qc # Output file prefix\n",
    "\n",
    "\n",
    "echo \"Extracted region: chr${CHR}:${REGION_START}-${REGION_END}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967cee8a",
   "metadata": {},
   "source": [
    "### **Step 4: Test Extracted Variants For Association With SLE Using Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412cdde4-0848-470a-858d-9a19f5249b8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "./plink2 \\\n",
    "  --pfile irf5_region_qc \\  # Input PLINK2 binary files from Step 3\n",
    "  --glm firth firth-residualize hide-covar \\  # Logistic regression: use Firth correction, residualize, hide covariate stats\n",
    "  --pheno ${PHENO_FILE} \\\n",
    "  --pheno-name has_sle_icd10 \\\n",
    "  --1 \\  # Recode case status: 1=case (PLINK default is 2=case)\n",
    "  --covar ${PHENO_FILE} \\\n",
    "  --covar-name sex age ethnic_group pc1 pc2 pc3 pc4 pc5 pc6 pc7 pc8 pc9 pc10 \\\n",
    "  --covar-variance-standardize \\  # Standardise covariates to mean=0, variance=1\n",
    "  --mac 20 \\  # Minimum minor allele count threshold\n",
    "  --threads 16 \\\n",
    "  --out irf5_sle  # Output file prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2feccc-d560-4e9d-a2fe-96bd7fa088de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# View first 20 results\n",
    "head -n 21 irf5_sle.has_sle_icd10.glm.firth\n",
    "\n",
    "# Expected columns: CHROM POS ID REF ALT A1 OMITTED A1_FREQ TEST OBS_CT OR LOG(OR)_SE Z_STAT P ERRCODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2bed75-94f6-406b-a232-6b877293526a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count variants with P < 5.7e-6 (Bonferroni-corrected significance threshold)\n",
    "awk 'NR>1 && $15 < 5.7e-6' irf5_sle.has_sle_icd10.glm.firth | wc -l # NR>1: skip header line; $15: P-value column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041c0914-bc5d-43cd-9b09-b743893ab12e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save all results sorted by p-value as CSV\n",
    "(head -n 1 irf5_sle.has_sle_icd10.glm.firth | tr '\\t' ',' && \\  # Extract header, convert tabs to commas\n",
    " tail -n +2 irf5_sle.has_sle_icd10.glm.firth | \\  # Get all data lines (skip header)\n",
    " sort -g -k15,15 | \\  # Sort by column 15 (P-value) in general numeric order\n",
    " tr '\\t' ',') > irf5_sle_results_sorted.csv  # Convert tabs to commas, save to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271bfe87",
   "metadata": {},
   "source": [
    "### **Step 5: Annotate Top 100 Variants With rsID And Nearest Gene**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e53b4-67fb-4ca5-a944-e493a1329141",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Python script to annotate top 100 variants with rsIDs\n",
    "cat > get_top100_rsids.py << 'EOF'\n",
    "import pandas as pd\n",
    "import requests # To make internet requests\n",
    "import time # To add delays\n",
    "\n",
    "# Read only top 100 variants (already sorted by p-value)\n",
    "df = pd.read_csv('irf5_sle_results_sorted.csv', nrows=100)\n",
    "\n",
    "print(f\"Processing top 100 variants by p-value...\")\n",
    "\n",
    "# Define function to make API request to get rsID based on variant chr & pos\n",
    "def get_rsid(chrom, pos):\n",
    "    url = f\"https://rest.ensembl.org/overlap/region/human/{chrom}:{pos}-{pos}?feature=variation\"\n",
    "    try:\n",
    "        response = requests.get(url, headers={\"Content-Type\": \"application/json\"}, timeout=10) # Want JSON format, give up if >10s\n",
    "        if response.ok:\n",
    "            data = response.json()\n",
    "            if data and len(data) > 0: # If got results and there's at least 1 variant\n",
    "                rsid = data[0].get('id', 'NA') # Get 'id' field of first result, if not 'NA'\n",
    "                return rsid\n",
    "        return 'NA'\n",
    "    except:\n",
    "        return 'NA'\n",
    "\n",
    "rsids = [] # Empty list to store results\n",
    "for idx, row in df.iterrows(): #idx (starts from 0) is the row number, row is the data within\n",
    "    chrom = row['#CHROM']\n",
    "    pos = row['POS']\n",
    "    rsid = get_rsid(chrom, pos)\n",
    "    rsids.append(rsid)\n",
    "    \n",
    "    if (idx + 1) % 10 == 0: \n",
    "        print(f\"Processed {idx+1}/100 variants...\")\n",
    "    \n",
    "    time.sleep(0.2) # Only 5 req/s to avoid overwhelming Ensembl API\n",
    "\n",
    "df['rsID'] = rsids # Create new column for rsIDs\n",
    "\n",
    "# Reorder columns\n",
    "cols = df.columns.tolist() # Get list of all column names\n",
    "id_idx = cols.index('ID')  # Find position of 'ID' column\n",
    "cols.insert(id_idx + 1, cols.pop(cols.index('rsID'))) # Move rsID to be right after ID\n",
    "df = df[cols] # Apply new column order\n",
    "\n",
    "# Save\n",
    "df.to_csv('irf5_top100_with_rsids.csv', index=False)\n",
    "\n",
    "# Summary\n",
    "total_rsids = sum(1 for r in rsids if r != 'NA' and r.startswith('rs'))\n",
    "print(f\"\\n=== Completed ===\")\n",
    "print(f\"Found {total_rsids} rsIDs out of 100 variants\")\n",
    "print(\"\\nTop 20 variants:\")\n",
    "print(df[['#CHROM', 'POS', 'ID', 'rsID', 'OR', 'P']].head(20))\n",
    "EOF\n",
    "\n",
    "# Run script\n",
    "python3 get_top100_rsids.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeba5c9",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Create Python script to annotate variants with genes\n",
    "cat > annotate_genes.py << 'EOF'\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Read rsID-annotated top 100 results\n",
    "df = pd.read_csv('irf5_top100_with_rsids.csv')\n",
    "\n",
    "print(f\"Annotating {len(df)} variants with gene names...\")\n",
    "\n",
    "def get_gene_annotation(chrom, pos, ref, alt):\n",
    "    \"\"\"\n",
    "    Query Ensembl VEP (Variant Effect Predictor) to determine if variant is inside a gene.\n",
    "    Returns gene name if variant is in a gene, 'regulatory_region' if in regulatory area,\n",
    "    or 'intergenic' if between genes.\n",
    "    \"\"\"\n",
    "    url = \"https://rest.ensembl.org/vep/human/region\"\n",
    "    \n",
    "    # Format variant location as: chr:start-end:strand/ref/alt\n",
    "    # Example: \"7:129013434-129013434:1/G/A\"\n",
    "    region = f\"{chrom}:{pos}-{pos}:1/{ref}/{alt}\"\n",
    "    \n",
    "    params = {\n",
    "        \"variant_class\": \"1\"  # Request variant classification information\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Query VEP API for variant annotation\n",
    "        response = requests.get(\n",
    "            f\"{url}/{region}\",\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            params=params,\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        if response.ok:\n",
    "            data = response.json()  # Parse JSON response\n",
    "            if data and len(data) > 0:\n",
    "                # Extract gene symbols from transcript consequences\n",
    "                genes = set()  # Use set to avoid duplicates\n",
    "                if 'transcript_consequences' in data[0]:\n",
    "                    # Loop through all affected transcripts\n",
    "                    for consequence in data[0]['transcript_consequences']:\n",
    "                        if 'gene_symbol' in consequence:\n",
    "                            genes.add(consequence['gene_symbol'])  # Collect unique gene names\n",
    "                \n",
    "                if genes:\n",
    "                    # If variant affects multiple genes, join with commas\n",
    "                    return ','.join(sorted(genes))\n",
    "                \n",
    "                # Check for intergenic consequences (variant between genes)\n",
    "                if 'intergenic_consequences' in data[0]:\n",
    "                    for consequence in data[0]['intergenic_consequences']:\n",
    "                        if 'consequence_terms' in consequence:\n",
    "                            if consequence.get('consequence_terms') == ['intergenic_variant']:\n",
    "                                # Placeholder for future nearest gene extraction from VEP\n",
    "                                pass\n",
    "                \n",
    "                # Check if variant is in a regulatory region (enhancer, promoter, etc.)\n",
    "                if 'regulatory_feature_consequences' in data[0]:\n",
    "                    return 'regulatory_region'\n",
    "                    \n",
    "        return 'intergenic'  # Not in any gene or regulatory region\n",
    "    except Exception as e:\n",
    "        return 'error'  # Return error if API call fails\n",
    "\n",
    "def get_nearest_gene(chrom, pos):\n",
    "    \"\"\"\n",
    "    For intergenic variants, find the nearest protein-coding gene within ±500kb.\n",
    "    Returns formatted string with gene name, distance, and direction.\n",
    "    \"\"\"\n",
    "    # Search 500kb flanking variant\n",
    "    window = 500000\n",
    "    start = pos - window\n",
    "    end = pos + window\n",
    "    \n",
    "    # Query Ensembl for all genes in the window\n",
    "    url = f\"https://rest.ensembl.org/overlap/region/human/{chrom}:{start}-{end}\"\n",
    "    params = {\n",
    "        \"feature\": \"gene\",  # Only return genes\n",
    "        \"biotype\": \"protein_coding\"  # Only protein-coding genes\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(\n",
    "            url,\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            params=params,\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        if response.ok:\n",
    "            genes = response.json()  # List of all genes in the window\n",
    "            if genes:\n",
    "                # Find gene with minimum distance to variant\n",
    "                min_distance = float('inf')  # Start with infinity\n",
    "                nearest = None\n",
    "                nearest_direction = None\n",
    "                \n",
    "                for gene in genes:\n",
    "                    gene_start = gene.get('start', 0)\n",
    "                    gene_end = gene.get('end', 0)\n",
    "                    gene_name = gene.get('external_name', gene.get('id', 'unknown'))\n",
    "                    \n",
    "                    # Calculate distance and direction from variant to gene\n",
    "                    if pos < gene_start:\n",
    "                        # Variant is upstream of gene\n",
    "                        distance = gene_start - pos\n",
    "                        direction = \"upstream\"\n",
    "                    elif pos > gene_end:\n",
    "                        # Variant is downstream of gene\n",
    "                        distance = pos - gene_end\n",
    "                        direction = \"downstream\"\n",
    "                    else:\n",
    "                        # Variant is inside the gene (but shouldn't happen for intergenic variants)\n",
    "                        distance = 0\n",
    "                        direction = \"in\"\n",
    "                    \n",
    "                    # Track the closest gene\n",
    "                    if distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                        nearest = gene_name\n",
    "                        nearest_direction = direction\n",
    "                \n",
    "                # Format output with distance and direction\n",
    "                if nearest and min_distance > 0:\n",
    "                    # Convert base pairs to kilobases (2 dp)\n",
    "                    return f\"{nearest} ({min_distance/1000:.2f}kb {nearest_direction})\"\n",
    "                elif nearest:\n",
    "                    # If distance is 0 (variant inside gene), just return gene name\n",
    "                    return nearest\n",
    "        \n",
    "        return 'intergenic'  # No genes found in window\n",
    "    except Exception as e:\n",
    "        return 'intergenic'  # Return intergenic if API call fails\n",
    "\n",
    "# Annotate all variants with gene information\n",
    "genes = []\n",
    "for idx, row in df.iterrows():\n",
    "    chrom = row['#CHROM']  # Chromosome number\n",
    "    pos = row['POS']  # Position on chromosome\n",
    "    ref = row['REF']  # Reference allele\n",
    "    alt = row['ALT']  # Alternate allele\n",
    "    \n",
    "    # Step 1: Check if variant is IN a gene using VEP\n",
    "    gene = get_gene_annotation(chrom, pos, ref, alt)\n",
    "    \n",
    "    # Step 2: If variant is intergenic, find nearest gene\n",
    "    if gene == 'intergenic':\n",
    "        gene = get_nearest_gene(chrom, pos)\n",
    "        time.sleep(0.3)  # Additional delay for second API call (600ms total per intergenic variant)\n",
    "    \n",
    "    genes.append(gene)\n",
    "    \n",
    "    # Progress update every 10 variants\n",
    "    if (idx + 1) % 10 == 0:\n",
    "        print(f\"Processed {idx+1}/{len(df)} variants... (last gene: {gene})\")\n",
    "    \n",
    "    time.sleep(0.3)  # 300ms delay between requests to avoid overwhelming API\n",
    "\n",
    "# Add Gene column to dataframe\n",
    "df['Gene'] = genes\n",
    "\n",
    "# Reorder columns to place Gene right after rsID for better readability\n",
    "cols = df.columns.tolist()  # Get list of all column names\n",
    "rsid_idx = cols.index('rsID')  # Find position of rsID column\n",
    "cols.insert(rsid_idx + 1, cols.pop(cols.index('Gene')))  # Move Gene to be after rsID\n",
    "df = df[cols]  # Apply new column order to df\n",
    "\n",
    "# Save annotated results\n",
    "df.to_csv('irf5_top100_annotated.csv', index=False)\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"\\n=== Completed ===\")\n",
    "print(f\"\\nSaved to: irf5_top100_annotated.csv\")\n",
    "print(\"\\nTop 20 variants with genes:\")\n",
    "print(df[['POS', 'rsID', 'Gene', 'OR', 'P']].head(20))  # Display key columns for top 20 variants\n",
    "EOF\n",
    "\n",
    "# Execute the Python script\n",
    "python3 annotate_genes.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
